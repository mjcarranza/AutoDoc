{"ast":null,"code":"import _asyncToGenerator from \"C:/Users/mario/Desktop/AutoDocIA/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport { __decorate } from \"tslib\";\nimport { Component } from '@angular/core';\nimport { Configuration, OpenAIApi } from 'openai';\nimport { environment } from 'src/environments/environment';\nimport { gptModels } from '../models/constants';\nlet CustomerSupportComponent = class CustomerSupportComponent {\n  constructor() {\n    this.chatConversation = [];\n    this.gptModels = gptModels;\n    this.promptText = '';\n    this.showSpinner = false;\n  }\n\n  ngOnInit() {}\n\n  checkResponse() {\n    this.pushChatContent(this.promptText, 'You', 'person');\n    this.invokeGPT();\n  }\n\n  pushChatContent(content, person, cssClass) {\n    const chatToPush = {\n      person: person,\n      response: content,\n      cssClass: cssClass\n    };\n    this.chatConversation.push(chatToPush);\n  }\n\n  getText(data) {\n    return data.split('\\n').filter(f => f.length > 0);\n  }\n\n  invokeGPT() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      if (_this.promptText.length < 2) return;\n\n      try {\n        _this.response = undefined;\n        let configuration = new Configuration({\n          apiKey: environment.apiKey\n        });\n        let openai = new OpenAIApi(configuration);\n        let requestData = {\n          model: 'text-davinci-003',\n          prompt: _this.promptText,\n          temperature: 0.95,\n          max_tokens: 150,\n          top_p: 1.0,\n          frequency_penalty: 0.0,\n          presence_penalty: 0.0\n        };\n        _this.showSpinner = true;\n        let apiResponse = yield openai.createCompletion(requestData);\n        _this.response = apiResponse.data;\n\n        _this.pushChatContent(_this.response.choices[0].text.trim(), 'Mr Bot', 'bot');\n\n        debugger;\n        _this.showSpinner = false;\n      } catch (error) {\n        _this.showSpinner = false; // Consider adjusting the error handling logic for your use case\n\n        if (error.response) {\n          console.error(error.response.status, error.response.data);\n        } else {\n          console.error(`Error with OpenAI API request: ${error.message}`);\n        }\n      }\n    })();\n  }\n\n};\nCustomerSupportComponent = __decorate([Component({\n  selector: 'app-customer-support',\n  templateUrl: './customer-support.component.html',\n  styleUrls: ['./customer-support.component.css']\n})], CustomerSupportComponent);\nexport { CustomerSupportComponent };","map":{"version":3,"mappings":";;AAAA,SAASA,SAAT,QAAkC,eAAlC;AACA,SAASC,aAAT,EAAwBC,SAAxB,QAAyC,QAAzC;AACA,SAASC,WAAT,QAA4B,8BAA5B;AACA,SAASC,SAAT,QAA0B,qBAA1B;AAQA,IAAaC,wBAAwB,GAArC,MAAaA,wBAAb,CAAqC;EAOnCC;IANF,wBAAgC,EAAhC;IAEI,iBAAYF,SAAZ;IACA,kBAAa,EAAb;IACA,mBAAc,KAAd;EAEe;;EAEjBG,QAAQ,IACP;;EAEDC,aAAa;IACX,KAAKC,eAAL,CAAqB,KAAKC,UAA1B,EAAqC,KAArC,EAA2C,QAA3C;IACA,KAAKC,SAAL;EACD;;EAGDF,eAAe,CAACG,OAAD,EAAiBC,MAAjB,EAAgCC,QAAhC,EAA+C;IAC5D,MAAMC,UAAU,GAAgB;MAAEF,MAAM,EAACA,MAAT;MAAiBG,QAAQ,EAACJ,OAA1B;MAAmCE,QAAQ,EAACA;IAA5C,CAAhC;IACA,KAAKG,gBAAL,CAAsBC,IAAtB,CAA2BH,UAA3B;EACD;;EAGDI,OAAO,CAACC,IAAD,EAAY;IACjB,OAAOA,IAAI,CAACC,KAAL,CAAW,IAAX,EAAiBC,MAAjB,CAAwBC,CAAC,IAAEA,CAAC,CAACC,MAAF,GAAS,CAApC,CAAP;EACD;;EAEKb,SAAS;IAAA;;IAAA;MAGb,IAAG,KAAI,CAACD,UAAL,CAAgBc,MAAhB,GAAuB,CAA1B,EACA;;MAIA,IAAG;QACD,KAAI,CAACR,QAAL,GAAgBS,SAAhB;QACA,IAAIC,aAAa,GAAG,IAAIzB,aAAJ,CAAkB;UAAC0B,MAAM,EAAExB,WAAW,CAACwB;QAArB,CAAlB,CAApB;QACA,IAAIC,MAAM,GAAG,IAAI1B,SAAJ,CAAcwB,aAAd,CAAb;QAEA,IAAIG,WAAW,GAAC;UACdC,KAAK,EAAE,kBADO;UAEdC,MAAM,EAAE,KAAI,CAACrB,UAFC;UAGdsB,WAAW,EAAE,IAHC;UAIdC,UAAU,EAAE,GAJE;UAKdC,KAAK,EAAE,GALO;UAMdC,iBAAiB,EAAE,GANL;UAOdC,gBAAgB,EAAE;QAPJ,CAAhB;QASA,KAAI,CAACC,WAAL,GAAmB,IAAnB;QACA,IAAIC,WAAW,SAAUV,MAAM,CAACW,gBAAP,CAAwBV,WAAxB,CAAzB;QAEA,KAAI,CAACb,QAAL,GAAgBsB,WAAW,CAAClB,IAA5B;;QACA,KAAI,CAACX,eAAL,CAAqB,KAAI,CAACO,QAAL,CAAcwB,OAAd,CAAsB,CAAtB,EAAyBC,IAAzB,CAA8BC,IAA9B,EAArB,EAA0D,QAA1D,EAAmE,KAAnE;;QACN;QACM,KAAI,CAACL,WAAL,GAAmB,KAAnB;MACD,CArBD,CAqBC,OAAMM,KAAN,EAAiB;QAChB,KAAI,CAACN,WAAL,GAAmB,KAAnB,CADgB,CAEhB;;QACA,IAAIM,KAAK,CAAC3B,QAAV,EAAoB;UAClB4B,OAAO,CAACD,KAAR,CAAcA,KAAK,CAAC3B,QAAN,CAAe6B,MAA7B,EAAqCF,KAAK,CAAC3B,QAAN,CAAeI,IAApD;QAED,CAHD,MAGO;UACLwB,OAAO,CAACD,KAAR,CAAc,kCAAkCA,KAAK,CAACG,OAAO,EAA7D;QAED;MACF;IAvCY;EAwCd;;AApEkC,CAArC;AAAazC,wBAAwB,eALpCL,SAAS,CAAC;EACT+C,QAAQ,EAAE,sBADD;EAETC,WAAW,EAAE,mCAFJ;EAGTC,SAAS,EAAE,CAAC,kCAAD;AAHF,CAAD,CAK2B,GAAxB5C,wBAAwB,CAAxB;SAAAA","names":["Component","Configuration","OpenAIApi","environment","gptModels","CustomerSupportComponent","constructor","ngOnInit","checkResponse","pushChatContent","promptText","invokeGPT","content","person","cssClass","chatToPush","response","chatConversation","push","getText","data","split","filter","f","length","undefined","configuration","apiKey","openai","requestData","model","prompt","temperature","max_tokens","top_p","frequency_penalty","presence_penalty","showSpinner","apiResponse","createCompletion","choices","text","trim","error","console","status","message","selector","templateUrl","styleUrls"],"sourceRoot":"","sources":["C:\\Users\\mario\\Desktop\\AutoDocIA\\src\\app\\customer-support\\customer-support.component.ts"],"sourcesContent":["import { Component, OnInit } from '@angular/core';\r\nimport { Configuration, OpenAIApi } from 'openai';\r\nimport { environment } from 'src/environments/environment';\r\nimport { gptModels } from '../models/constants';\r\nimport { ChatWithBot, ResponseModel } from '../models/gpt-response';\r\n\r\n@Component({\r\n  selector: 'app-customer-support',\r\n  templateUrl: './customer-support.component.html',\r\n  styleUrls: ['./customer-support.component.css']\r\n})\r\nexport class CustomerSupportComponent implements OnInit {\r\nchatConversation: ChatWithBot[]=[];\r\nresponse!: ResponseModel | undefined;\r\n    gptModels = gptModels\r\n    promptText = '';\r\n    showSpinner = false;\r\n\r\n  constructor() { }\r\n\r\n  ngOnInit(): void {\r\n  }\r\n\r\n  checkResponse() {\r\n    this.pushChatContent(this.promptText,'You','person');\r\n    this.invokeGPT();\r\n  }\r\n\r\n\r\n  pushChatContent(content:string, person:string, cssClass:string) {\r\n    const chatToPush: ChatWithBot = { person:person, response:content, cssClass:cssClass};\r\n    this.chatConversation.push(chatToPush);\r\n  }\r\n\r\n\r\n  getText(data:string) {\r\n    return data.split('\\n').filter(f=>f.length>0);\r\n  }\r\n\r\n  async invokeGPT() {\r\n   \r\n\r\n    if(this.promptText.length<2)\r\n    return;\r\n\r\n    \r\n\r\n    try{\r\n      this.response = undefined;\r\n      let configuration = new Configuration({apiKey: environment.apiKey});\r\n      let openai = new OpenAIApi(configuration);\r\n\r\n      let requestData={\r\n        model: 'text-davinci-003',//'text-davinci-003',//\"text-curie-001\",\r\n        prompt: this.promptText,//this.generatePrompt(animal),\r\n        temperature: 0.95,\r\n        max_tokens: 150,\r\n        top_p: 1.0,\r\n        frequency_penalty: 0.0,\r\n        presence_penalty: 0.0,\r\n      };\r\n      this.showSpinner = true;\r\n      let apiResponse =  await openai.createCompletion(requestData);\r\n\r\n      this.response = apiResponse.data as ResponseModel;\r\n      this.pushChatContent(this.response.choices[0].text.trim(),'Mr Bot','bot');\r\ndebugger;\r\n      this.showSpinner = false;\r\n    }catch(error:any) {\r\n      this.showSpinner = false;\r\n      // Consider adjusting the error handling logic for your use case\r\n      if (error.response) {\r\n        console.error(error.response.status, error.response.data);\r\n        \r\n      } else {\r\n        console.error(`Error with OpenAI API request: ${error.message}`);\r\n        \r\n      }\r\n    }\r\n  }\r\n}\r\n"]},"metadata":{},"sourceType":"module"}