{"ast":null,"code":"import _asyncToGenerator from \"C:/Users/mario/Desktop/AutoDocIA/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport { Configuration, OpenAIApi } from 'openai';\nimport { environment } from 'src/environments/environment';\nimport { gptModels } from '../models/constants';\nimport * as i0 from \"@angular/core\";\nimport * as i1 from \"@angular/common\";\n\nfunction CustomerSupportComponent_img_8_Template(rf, ctx) {\n  if (rf & 1) {\n    i0.ɵɵelement(0, \"img\", 6);\n  }\n\n  if (rf & 2) {\n    const ctx_r0 = i0.ɵɵnextContext();\n    i0.ɵɵproperty(\"src\", ctx_r0.selectedImage, i0.ɵɵsanitizeUrl);\n  }\n}\n\nexport class CustomerSupportComponent {\n  constructor() {\n    this.chatConversation = [];\n    this.gptModels = gptModels;\n    this.promptText = '';\n    this.showSpinner = false;\n  }\n\n  ngOnInit() {}\n\n  checkResponse() {\n    this.pushChatContent(this.promptText, 'You', 'person');\n    this.invokeGPT();\n  }\n\n  pushChatContent(content, person, cssClass) {\n    const chatToPush = {\n      person: person,\n      response: content,\n      cssClass: cssClass\n    };\n    this.chatConversation.push(chatToPush);\n  }\n\n  getText(data) {\n    return data.split('\\n').filter(f => f.length > 0);\n  }\n\n  invokeGPT() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      if (_this.promptText.length < 2) return;\n\n      try {\n        _this.response = undefined;\n        let configuration = new Configuration({\n          apiKey: environment.apiKey\n        });\n        let openai = new OpenAIApi(configuration);\n        let requestData = {\n          model: 'text-davinci-003',\n          prompt: _this.promptText,\n          temperature: 0.95,\n          max_tokens: 150,\n          top_p: 1.0,\n          frequency_penalty: 0.0,\n          presence_penalty: 0.0\n        };\n        _this.showSpinner = true;\n        let apiResponse = yield openai.createCompletion(requestData);\n        _this.response = apiResponse.data;\n\n        _this.pushChatContent(_this.response.choices[0].text.trim(), 'Mr Bot', 'bot');\n\n        debugger;\n        _this.showSpinner = false;\n      } catch (error) {\n        _this.showSpinner = false; // Consider adjusting the error handling logic for your use case\n\n        if (error.response) {\n          console.error(error.response.status, error.response.data);\n        } else {\n          console.error(`Error with OpenAI API request: ${error.message}`);\n        }\n      }\n    })();\n  }\n\n}\n\nCustomerSupportComponent.ɵfac = function CustomerSupportComponent_Factory(t) {\n  return new (t || CustomerSupportComponent)();\n};\n\nCustomerSupportComponent.ɵcmp = /*@__PURE__*/i0.ɵɵdefineComponent({\n  type: CustomerSupportComponent,\n  selectors: [[\"app-customer-support\"]],\n  decls: 9,\n  vars: 1,\n  consts: [[1, \"container\", \"mt-4\"], [1, \"custom-file\"], [\"type\", \"file\", \"id\", \"customFile\", 1, \"custom-file-input\", 3, \"change\"], [\"for\", \"customFile\", 1, \"custom-file-label\"], [1, \"mt-3\"], [\"alt\", \"Vista previa de la imagen\", \"class\", \"img-thumbnail\", 3, \"src\", 4, \"ngIf\"], [\"alt\", \"Vista previa de la imagen\", 1, \"img-thumbnail\", 3, \"src\"]],\n  template: function CustomerSupportComponent_Template(rf, ctx) {\n    if (rf & 1) {\n      i0.ɵɵelementStart(0, \"div\", 0)(1, \"h2\");\n      i0.ɵɵtext(2, \"Subir una imagen\");\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(3, \"div\", 1)(4, \"input\", 2);\n      i0.ɵɵlistener(\"change\", function CustomerSupportComponent_Template_input_change_4_listener($event) {\n        return ctx.onFileSelected($event);\n      });\n      i0.ɵɵelementEnd();\n      i0.ɵɵelementStart(5, \"label\", 3);\n      i0.ɵɵtext(6, \"Selecciona un archivo\");\n      i0.ɵɵelementEnd()();\n      i0.ɵɵelementStart(7, \"div\", 4);\n      i0.ɵɵtemplate(8, CustomerSupportComponent_img_8_Template, 1, 1, \"img\", 5);\n      i0.ɵɵelementEnd()();\n    }\n\n    if (rf & 2) {\n      i0.ɵɵadvance(8);\n      i0.ɵɵproperty(\"ngIf\", ctx.selectedImage);\n    }\n  },\n  dependencies: [i1.NgIf],\n  styles: [\".push-right[_ngcontent-%COMP%] {\\r\\n    margin-left: 90%;\\r\\n}\\r\\n\\r\\n.person[_ngcontent-%COMP%] {\\r\\n    font-style: italic;\\r\\n    font-weight: bold;\\r\\n    color: purple;\\r\\n}\\r\\n\\r\\n.bot[_ngcontent-%COMP%] {    \\r\\n    font-weight: bold; \\r\\n    color: darkgreen;\\r\\n}\\r\\n\\r\\n.frame-box[_ngcontent-%COMP%]{\\r\\n    border: dotted 2px orange; padding: 20px;\\r\\n    min-height: 400px;\\r\\n    max-height: 400px;\\r\\n    overflow-y: scroll\\r\\n}\\r\\n\\r\\n.padding[_ngcontent-%COMP%]{\\r\\n    padding: 5px;\\r\\n}\\n/*# sourceMappingURL=data:application/json;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VzIjpbImN1c3RvbWVyLXN1cHBvcnQuY29tcG9uZW50LmNzcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQTtJQUNJLGdCQUFnQjtBQUNwQjs7QUFFQTtJQUNJLGtCQUFrQjtJQUNsQixpQkFBaUI7SUFDakIsYUFBYTtBQUNqQjs7QUFFQTtJQUNJLGlCQUFpQjtJQUNqQixnQkFBZ0I7QUFDcEI7O0FBRUE7SUFDSSx5QkFBeUIsRUFBRSxhQUFhO0lBQ3hDLGlCQUFpQjtJQUNqQixpQkFBaUI7SUFDakI7QUFDSjs7QUFHQTtJQUNJLFlBQVk7QUFDaEIiLCJmaWxlIjoiY3VzdG9tZXItc3VwcG9ydC5jb21wb25lbnQuY3NzIiwic291cmNlc0NvbnRlbnQiOlsiLnB1c2gtcmlnaHQge1xyXG4gICAgbWFyZ2luLWxlZnQ6IDkwJTtcclxufVxyXG5cclxuLnBlcnNvbiB7XHJcbiAgICBmb250LXN0eWxlOiBpdGFsaWM7XHJcbiAgICBmb250LXdlaWdodDogYm9sZDtcclxuICAgIGNvbG9yOiBwdXJwbGU7XHJcbn1cclxuXHJcbi5ib3QgeyAgICBcclxuICAgIGZvbnQtd2VpZ2h0OiBib2xkOyBcclxuICAgIGNvbG9yOiBkYXJrZ3JlZW47XHJcbn1cclxuXHJcbi5mcmFtZS1ib3h7XHJcbiAgICBib3JkZXI6IGRvdHRlZCAycHggb3JhbmdlOyBwYWRkaW5nOiAyMHB4O1xyXG4gICAgbWluLWhlaWdodDogNDAwcHg7XHJcbiAgICBtYXgtaGVpZ2h0OiA0MDBweDtcclxuICAgIG92ZXJmbG93LXk6IHNjcm9sbFxyXG59XHJcblxyXG5cclxuLnBhZGRpbmd7XHJcbiAgICBwYWRkaW5nOiA1cHg7XHJcbn0iXX0= */\"]\n});","map":{"version":3,"mappings":";AACA,SAASA,aAAT,EAAwBC,SAAxB,QAAyC,QAAzC;AACA,SAASC,WAAT,QAA4B,8BAA5B;AACA,SAASC,SAAT,QAA0B,qBAA1B;;;;;;ICKMC;;;;;IAA2BA;;;;ADGjC,OAAM,MAAOC,wBAAP,CAA+B;EAOnCC;IANF,wBAAgC,EAAhC;IAEI,iBAAYH,SAAZ;IACA,kBAAa,EAAb;IACA,mBAAc,KAAd;EAEe;;EAEjBI,QAAQ,IACP;;EAEDC,aAAa;IACX,KAAKC,eAAL,CAAqB,KAAKC,UAA1B,EAAqC,KAArC,EAA2C,QAA3C;IACA,KAAKC,SAAL;EACD;;EAGDF,eAAe,CAACG,OAAD,EAAiBC,MAAjB,EAAgCC,QAAhC,EAA+C;IAC5D,MAAMC,UAAU,GAAgB;MAAEF,MAAM,EAACA,MAAT;MAAiBG,QAAQ,EAACJ,OAA1B;MAAmCE,QAAQ,EAACA;IAA5C,CAAhC;IACA,KAAKG,gBAAL,CAAsBC,IAAtB,CAA2BH,UAA3B;EACD;;EAGDI,OAAO,CAACC,IAAD,EAAY;IACjB,OAAOA,IAAI,CAACC,KAAL,CAAW,IAAX,EAAiBC,MAAjB,CAAwBC,CAAC,IAAEA,CAAC,CAACC,MAAF,GAAS,CAApC,CAAP;EACD;;EAEKb,SAAS;IAAA;;IAAA;MAGb,IAAG,KAAI,CAACD,UAAL,CAAgBc,MAAhB,GAAuB,CAA1B,EACA;;MAIA,IAAG;QACD,KAAI,CAACR,QAAL,GAAgBS,SAAhB;QACA,IAAIC,aAAa,GAAG,IAAI1B,aAAJ,CAAkB;UAAC2B,MAAM,EAAEzB,WAAW,CAACyB;QAArB,CAAlB,CAApB;QACA,IAAIC,MAAM,GAAG,IAAI3B,SAAJ,CAAcyB,aAAd,CAAb;QAEA,IAAIG,WAAW,GAAC;UACdC,KAAK,EAAE,kBADO;UAEdC,MAAM,EAAE,KAAI,CAACrB,UAFC;UAGdsB,WAAW,EAAE,IAHC;UAIdC,UAAU,EAAE,GAJE;UAKdC,KAAK,EAAE,GALO;UAMdC,iBAAiB,EAAE,GANL;UAOdC,gBAAgB,EAAE;QAPJ,CAAhB;QASA,KAAI,CAACC,WAAL,GAAmB,IAAnB;QACA,IAAIC,WAAW,SAAUV,MAAM,CAACW,gBAAP,CAAwBV,WAAxB,CAAzB;QAEA,KAAI,CAACb,QAAL,GAAgBsB,WAAW,CAAClB,IAA5B;;QACA,KAAI,CAACX,eAAL,CAAqB,KAAI,CAACO,QAAL,CAAcwB,OAAd,CAAsB,CAAtB,EAAyBC,IAAzB,CAA8BC,IAA9B,EAArB,EAA0D,QAA1D,EAAmE,KAAnE;;QACN;QACM,KAAI,CAACL,WAAL,GAAmB,KAAnB;MACD,CArBD,CAqBC,OAAMM,KAAN,EAAiB;QAChB,KAAI,CAACN,WAAL,GAAmB,KAAnB,CADgB,CAEhB;;QACA,IAAIM,KAAK,CAAC3B,QAAV,EAAoB;UAClB4B,OAAO,CAACD,KAAR,CAAcA,KAAK,CAAC3B,QAAN,CAAe6B,MAA7B,EAAqCF,KAAK,CAAC3B,QAAN,CAAeI,IAApD;QAED,CAHD,MAGO;UACLwB,OAAO,CAACD,KAAR,CAAc,kCAAkCA,KAAK,CAACG,OAAO,EAA7D;QAED;MACF;IAvCY;EAwCd;;AApEkC;;;mBAAxBzC;AAAwB;;;QAAxBA;EAAwB0C;EAAAC;EAAAC;EAAAC;EAAAC;IAAA;MCXrC/C,+BAA4B,CAA5B,EAA4B,IAA5B;MACQA;MAAgBA;MACpBA,+BAAyB,CAAzB,EAAyB,OAAzB,EAAyB,CAAzB;MAC+DA;QAAA,OAAUgD,0BAAV;MAAgC,CAAhC;MAA7DhD;MACAA;MAAkDA;MAAqBA;MAGzEA;MACEA;MACFA;;;;MADQA;MAAAA","names":["Configuration","OpenAIApi","environment","gptModels","i0","CustomerSupportComponent","constructor","ngOnInit","checkResponse","pushChatContent","promptText","invokeGPT","content","person","cssClass","chatToPush","response","chatConversation","push","getText","data","split","filter","f","length","undefined","configuration","apiKey","openai","requestData","model","prompt","temperature","max_tokens","top_p","frequency_penalty","presence_penalty","showSpinner","apiResponse","createCompletion","choices","text","trim","error","console","status","message","selectors","decls","vars","consts","template","ctx"],"sourceRoot":"","sources":["C:\\Users\\mario\\Desktop\\AutoDocIA\\src\\app\\customer-support\\customer-support.component.ts","C:\\Users\\mario\\Desktop\\AutoDocIA\\src\\app\\customer-support\\customer-support.component.html"],"sourcesContent":["import { Component, OnInit } from '@angular/core';\r\nimport { Configuration, OpenAIApi } from 'openai';\r\nimport { environment } from 'src/environments/environment';\r\nimport { gptModels } from '../models/constants';\r\nimport { ChatWithBot, ResponseModel } from '../models/gpt-response';\r\n\r\n@Component({\r\n  selector: 'app-customer-support',\r\n  templateUrl: './customer-support.component.html',\r\n  styleUrls: ['./customer-support.component.css']\r\n})\r\nexport class CustomerSupportComponent implements OnInit {\r\nchatConversation: ChatWithBot[]=[];\r\nresponse!: ResponseModel | undefined;\r\n    gptModels = gptModels\r\n    promptText = '';\r\n    showSpinner = false;\r\n\r\n  constructor() { }\r\n\r\n  ngOnInit(): void {\r\n  }\r\n\r\n  checkResponse() {\r\n    this.pushChatContent(this.promptText,'You','person');\r\n    this.invokeGPT();\r\n  }\r\n\r\n\r\n  pushChatContent(content:string, person:string, cssClass:string) {\r\n    const chatToPush: ChatWithBot = { person:person, response:content, cssClass:cssClass};\r\n    this.chatConversation.push(chatToPush);\r\n  }\r\n\r\n\r\n  getText(data:string) {\r\n    return data.split('\\n').filter(f=>f.length>0);\r\n  }\r\n\r\n  async invokeGPT() {\r\n   \r\n\r\n    if(this.promptText.length<2)\r\n    return;\r\n\r\n    \r\n\r\n    try{\r\n      this.response = undefined;\r\n      let configuration = new Configuration({apiKey: environment.apiKey});\r\n      let openai = new OpenAIApi(configuration);\r\n\r\n      let requestData={\r\n        model: 'text-davinci-003',//'text-davinci-003',//\"text-curie-001\",\r\n        prompt: this.promptText,//this.generatePrompt(animal),\r\n        temperature: 0.95,\r\n        max_tokens: 150,\r\n        top_p: 1.0,\r\n        frequency_penalty: 0.0,\r\n        presence_penalty: 0.0,\r\n      };\r\n      this.showSpinner = true;\r\n      let apiResponse =  await openai.createCompletion(requestData);\r\n\r\n      this.response = apiResponse.data as ResponseModel;\r\n      this.pushChatContent(this.response.choices[0].text.trim(),'Mr Bot','bot');\r\ndebugger;\r\n      this.showSpinner = false;\r\n    }catch(error:any) {\r\n      this.showSpinner = false;\r\n      // Consider adjusting the error handling logic for your use case\r\n      if (error.response) {\r\n        console.error(error.response.status, error.response.data);\r\n        \r\n      } else {\r\n        console.error(`Error with OpenAI API request: ${error.message}`);\r\n        \r\n      }\r\n    }\r\n  }\r\n}\r\n","<div class=\"container mt-4\">\r\n    <h2>Subir una imagen</h2>\r\n    <div class=\"custom-file\">\r\n      <input type=\"file\" class=\"custom-file-input\" id=\"customFile\" (change)=\"onFileSelected($event)\">\r\n      <label class=\"custom-file-label\" for=\"customFile\">Selecciona un archivo</label>\r\n    </div>\r\n  \r\n    <div class=\"mt-3\">\r\n      <img *ngIf=\"selectedImage\" [src]=\"selectedImage\" alt=\"Vista previa de la imagen\" class=\"img-thumbnail\">\r\n    </div>\r\n  </div>"]},"metadata":{},"sourceType":"module"}